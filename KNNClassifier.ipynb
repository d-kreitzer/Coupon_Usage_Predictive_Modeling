{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f282a5-f562-48a5-b060-d675ea3c3308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95388a4c-625e-485d-8ae7-ab4bdda21f74",
   "metadata": {},
   "source": [
    "## KNN Classifier Model\n",
    "\n",
    "In this section, we delve into the K-Nearest Neighbors (KNN) algorithm, a straightforward yet powerful classification method. The KNN algorithm classifies new examples based on the majority class of the 'k' nearest points from the training dataset. This simplicity makes KNN a versatile choice for a wide range of classification problems.\n",
    "\n",
    "## Key Characteristics of KNN:\n",
    "\n",
    "- **Non-parametric**: KNN makes no assumptions about the underlying data distribution, which is useful with real-world data that can be complex and messy.\n",
    "- **Lazy Learning**: It doesn't explicitly learn a model. Instead, it classifies instances based on their similarity to other instances present in the training dataset.\n",
    "- **Distance Metric**: The algorithm uses a distance metric, typically Euclidean, to identify the 'k' closest instances (neighbors).\n",
    "\n",
    "By adjusting the number of neighbors ('k') and the distance metric, we can fine-tune KNN to achieve substantial performance across various datasets and contexts.\n",
    "\n",
    "The purpose of this notebook is to create and tune a KNN Classifier model and then pickle that model for a future full-fledged comparison.\n",
    "\n",
    "To see a full breakdown of the establishment of our code, refer to the notebook \"Final_Project_Data_Gen.\"\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2758c875",
   "metadata": {},
   "source": [
    "Here is where we will establish our custom `scorer`. We have decided to use a custom F2 score to prioritize recall (minimizing the chance of not giving a coupon to someone who would use it) while considering the value of precision (minimizing the chance of giving a coupon to someone who will not use it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e95ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_func(y_true, y_pred):\n",
    "    f2_score = fbeta_score(y_true, y_pred, beta=2, average=\"weighted\")\n",
    "    return f2_score\n",
    "\n",
    "\n",
    "def my_f2_scorer():\n",
    "    return make_scorer(f2_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6199479",
   "metadata": {},
   "source": [
    "Import the pre-split data files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396ae859-f9d6-4221-9e39-e8ecd3910872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"train_X_In-Car-Rec.csv\")\n",
    "y_train = pd.read_csv(\"train_y_In-Car-Rec.csv\")\n",
    "X_test = pd.read_csv(\"test_X_In-Car-Rec.csv\")\n",
    "y_test = pd.read_csv(\"test_y_In-Car-Rec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee558644",
   "metadata": {},
   "source": [
    "We calculate the square root of the number of training samples in our dataset using `np.sqrt(X_train.shape[0])`, and then round this number to the nearest whole number with `round()`. This value is often used to determine an optimal 'k' for K-Nearest Neighbors (KNN) classifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd8f229a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.sqrt(X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd874f7",
   "metadata": {},
   "source": [
    "We've set up a `param_grid` dictionary for hyperparameter tuning of our KNN classifier. The grid includes two hyperparameters:\n",
    "\n",
    "- `n_neighbors`: We're considering a range of values from 1 to 100, incremented by 5, to find the optimal number of nearest neighbors.\n",
    "- `metric`: We're testing both 'euclidean' and 'cosine' distance metrics to see which one provides better results for our model.\n",
    "\n",
    "This parameter grid will be used to systematically explore different combinations of `n_neighbors` and `metric` in the search for the best-performing KNN classifier configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c197f221-1ead-448e-8a94-991f312bbedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\"n_neighbors\": list(range(1, 101, 5)), \"metric\": [\"euclidean\", \"cosine\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb037ff",
   "metadata": {},
   "source": [
    "We are constructing a machine learning pipeline that encapsulates the K-Nearest Neighbors (KNN) classifier. Here's a brief outline of our approach:\n",
    "\n",
    "- **Pipeline Creation**: We use the `Pipeline` class from Scikit-learn's `pipeline` module to create a sequence of transformations and a final estimator.\n",
    "- **KNN Initialization**: Within the pipeline, we initialize the `KNeighborsClassifier` as the step named `\"knn\"`. This step is set to be the final estimator in our pipeline.\n",
    "\n",
    "The pipeline is designed to ensure a streamlined process where any additional steps, such as preprocessing or dimensionality reduction, can be easily added in the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05969f88-067e-486c-8164-dd752bf9e016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the full pipeline\n",
    "pipeline = Pipeline([(\"knn\", KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c655a02",
   "metadata": {},
   "source": [
    "We create a GridSearchCV object with our KNN classifier and a predefined grid of hyperparameters to determine the best combination through 10-fold cross-validation, using a custom F2 scorer for optimization. Then, we fit this grid search to our training data, X_train and y_train, which tunes the hyperparameters of the KNN model to maximize the F2 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e4fbbd-5341-4b4a-aa89-cac505fbd891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;cosine&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [1, 6, 11, 16, 21, 26, 31, 36, 41, 46,\n",
       "                                         51, 56, 61, 66, 71, 76, 81, 86, 91,\n",
       "                                         96]},\n",
       "             scoring=make_scorer(f2_func))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;cosine&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [1, 6, 11, 16, 21, 26, 31, 36, 41, 46,\n",
       "                                         51, 56, 61, 66, 71, 76, 81, 86, 91,\n",
       "                                         96]},\n",
       "             scoring=make_scorer(f2_func))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'metric': ['euclidean', 'cosine'],\n",
       "                         'n_neighbors': [1, 6, 11, 16, 21, 26, 31, 36, 41, 46,\n",
       "                                         51, 56, 61, 66, 71, 76, 81, 86, 91,\n",
       "                                         96]},\n",
       "             scoring=make_scorer(f2_func))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    KNeighborsClassifier(), param_grid, cv=10, scoring=my_f2_scorer(), n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the pipeline (including hyperparameter tuning) to your data\n",
    "grid_search.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd9e8a",
   "metadata": {},
   "source": [
    "We save the best-performing model from the grid search as best_estimator. We also retrieve the optimal hyperparameters and the corresponding best cross-validation score, storing them in best_params and best_score, respectively. This allows us to inspect the most effective configuration and its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1af0c9ef-b5a0-4706-be2a-d796bf9d0bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'metric': 'euclidean', 'n_neighbors': 36}, 0.6980771345788905)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store best estimator\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb992a30",
   "metadata": {},
   "source": [
    "We initialize a new KNeighborsClassifier instance and apply the optimal hyperparameters found by the grid search. By unpacking best_params with \\*\\*, we set these parameters directly on the KNN classifier, effectively configuring it with the settings that yielded the best cross-validation performance during the tuning process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a93f961-5f76-40ac-929d-4afcec1e8040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=36)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=36)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_neighbors=36)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.set_params(**best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c1e62",
   "metadata": {},
   "source": [
    "We train our KNN classifier with the best hyperparameters obtained from the grid search on the training dataset X_train and the target values y_train. By calling ravel() on y_train, we ensure that the target data is in the appropriate shape expected by the fit method, which is a one-dimensional array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "505e4ff2-896b-438a-b440-6f55017ff81a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=36)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_neighbors=36)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_neighbors=36)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the final pipeline\n",
    "knn.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351a036",
   "metadata": {},
   "source": [
    "Using our trained KNN classifier to make predictions on the test dataset X_test. The predicted labels for each instance in the test set are stored in the variable y_pred.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8499070-e7b8-43b6-92f4-41696b802099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7099c5f",
   "metadata": {},
   "source": [
    "## Evaluate the model's performance\n",
    "\n",
    "To evaluate the performance of our trained KNN classifier on the test data X_test by calculating the default accuracy score, which is stored in the variable score. Additionally, we compute the F2 score, which gives more weight to recall than precision, using the fbeta_score function with a beta of 2. This weighted F2 score is particularly useful when false negatives carry a higher cost than false positives. The calculated F2 score for our KNN model is then printed out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d91333a4-1596-425e-bd71-6dc01817379a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2Score for the KNN Model is: 0.707296744500565\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the pipeline on the test data\n",
    "score = knn.score(X_test, y_test)\n",
    "\n",
    "# Calculate f1_score on the test data\n",
    "f2_score = fbeta_score(y_test, y_pred, average=\"weighted\", beta=2)\n",
    "print(f\"F2Score for the KNN Model is: \" + str(f2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've computed the F2 score for our KNN model, which came out to be approximately 0.707. This suggests that our model has a reasonably good balance between precision and recall, with a particular emphasis on reducing false negatives, as the F2 score weighs recall higher than precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee911e0",
   "metadata": {},
   "source": [
    "Let's display the confusion matrix and our accuracy, precision, and recall for the KNN model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b766858-66ef-4b29-bd5c-1ecd9cc5397c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 632  446]\n",
      " [ 291 1168]]\n",
      "\n",
      "Precision (weighted): 0.7071\n",
      "Recall (weighted): 0.7095\n",
      "Accuracy: 0.7095\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "print(f\"\\nPrecision (weighted): {precision:.4f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "print(f\"Recall (weighted): {recall:.4f}\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have analyzed the performance of our model using a confusion matrix and other classification metrics. The confusion matrix shows that we have 632 true negatives and 1168 true positives, indicating instances correctly identified by our model. However, there are also 446 false positives and 291 false negatives, where our model's predictions were incorrect.\n",
    "\n",
    "The precision of our model, calculated as the weighted average due to class imbalance, is 0.7071. This means that when our model predicts a positive outcome, it is correct about 70.71% of the time. Our model's recall, also weighted, is 0.7095, which tells us that it correctly identifies 70.95% of all positive instances.\n",
    "\n",
    "Lastly, the accuracy of our model is 0.7095, meaning that it makes the correct prediction for approximately 70.95% of the cases. Considering these metrics together gives us insight into the areas where our model performs well and where there may be room for improvement, especially in reducing the number of false positives and false negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling Our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final pipeline\n",
    "\n",
    "pipeline_knnClassifier = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"knn\",\n",
    "            KNeighborsClassifier(metric=\"euclidean\", n_neighbors=36),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename where you want to save the model\n",
    "filename = \"KNNClassifier_Model.pkl\"\n",
    "\n",
    "# Export the model to the file using pickle.dump\n",
    "with open(filename, \"wb\") as file:\n",
    "    pickle.dump(pipeline_knnClassifier, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
