{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c0eae21-3e02-4be8-965b-627d311cd6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, fbeta_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier\n",
    "\n",
    "In this section, we venture into the world of Extreme Gradient Boosting (XGBoost), a robust and highly efficient machine learning algorithm known for its superior performance in classification and regression tasks. XGBoost stands out for its ability to handle complex datasets, automatically handling missing values, and minimizing overfitting through regularization techniques.\n",
    "\n",
    "## Key Characteristics of XGBoost:\n",
    "\n",
    "- **Gradient Boosting**: XGBoost employs a gradient boosting framework, sequentially adding decision trees that correct the errors of the previous trees.\n",
    "- **Regularization**: The algorithm incorporates L1 and L2 regularization terms to prevent overfitting, enhancing its generalization capability.\n",
    "- **Speed and Efficiency**: XGBoost is optimized for speed and efficiency, making it a top choice for large datasets.\n",
    "\n",
    "XGBoost has demonstrated its effectiveness in numerous machine learning competitions and real-world applications, making it a formidable tool for classification challenges.\n",
    "\n",
    "In this section, we will delve into the development, fine-tuning, and evaluation of an XGBoost Classifier tailored to our specific dataset. This will prepare us for later comparisons with other classification models.\n",
    "\n",
    "For a comprehensive guide to our implementation, please refer to the notebook \"Final_Project_Data_Gen.\"\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our dataset from CSV files, with `X_train` and `y_train` as our training features and labels, and `X_test` and `y_test` for testing, using Pandas DataFrames to facilitate data manipulation and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0c6db8-bff7-4d09-9490-a41973417108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cleaned train and test data\n",
    "X_train = pd.read_csv(\"train_X_In-Car-Rec.csv\")\n",
    "y_train = pd.read_csv(\"train_y_In-Car-Rec.csv\")\n",
    "X_test = pd.read_csv(\"test_X_In-Car-Rec.csv\")\n",
    "y_test = pd.read_csv(\"test_y_In-Car-Rec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the columns of our training dataset, `X_train`, to inspect the feature names and gain a better understanding of the available input variables, helping us verify data integrity and plan our analysis effectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5255f960-972f-4511-ba53-3fea928faebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TEMPERATURE', 'HAS_CHILDREN', 'TOCOUPON_GEQ5MIN', 'TOCOUPON_GEQ15MIN',\n",
       "       'TOCOUPON_GEQ25MIN', 'DIRECTION_SAME', 'DIRECTION_OPP',\n",
       "       'DESTINATION_HOME', 'DESTINATION_NO_URGENT_PLACE', 'DESTINATION_WORK',\n",
       "       ...\n",
       "       'RESTAURANTLESSTHAN20_1~3', 'RESTAURANTLESSTHAN20_4~8',\n",
       "       'RESTAURANTLESSTHAN20_GT8', 'RESTAURANTLESSTHAN20_LESS1',\n",
       "       'RESTAURANTLESSTHAN20_NEVER', 'RESTAURANT20TO50_1~3',\n",
       "       'RESTAURANT20TO50_4~8', 'RESTAURANT20TO50_GT8',\n",
       "       'RESTAURANT20TO50_LESS1', 'RESTAURANT20TO50_NEVER'],\n",
       "      dtype='object', length=109)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View columns to spot check values\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll ensure that the imported data is complete and correctly loaded by displaying the shapes of our training and test datasets, `X_train`, `y_train`, `X_test`, and `y_test`. These shape dimensions allow us to confirm that the data has been successfully loaded and is consistent with our expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2221b25-061d-465d-bb3e-f6534df840f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10147, 109)\n",
      "(10147, 1)\n",
      "(2537, 109)\n",
      "(2537, 1)\n"
     ]
    }
   ],
   "source": [
    "# Verify imported data is complete\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a check to verify that the columns have been imported correctly, as sometimes an additional index column may be present when writing data to a CSV file. We examine the first few rows of our training and test datasets, `X_train`, `y_train`, `X_test`, and `y_test`, to ensure that the data columns match our expectations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d456e588-ca26-4ed5-b9a1-1730daecc647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TEMPERATURE  HAS_CHILDREN  TOCOUPON_GEQ5MIN  TOCOUPON_GEQ15MIN  \\\n",
      "0         80.0           0.0               1.0                1.0   \n",
      "1         30.0           1.0               1.0                0.0   \n",
      "2         55.0           0.0               1.0                0.0   \n",
      "3         55.0           0.0               1.0                1.0   \n",
      "4         80.0           0.0               1.0                1.0   \n",
      "\n",
      "   TOCOUPON_GEQ25MIN  DIRECTION_SAME  DIRECTION_OPP  DESTINATION_HOME  \\\n",
      "0                0.0             0.0            1.0                 0   \n",
      "1                0.0             0.0            1.0                 0   \n",
      "2                0.0             1.0            0.0                 0   \n",
      "3                1.0             0.0            1.0                 0   \n",
      "4                0.0             0.0            1.0                 0   \n",
      "\n",
      "   DESTINATION_NO_URGENT_PLACE  DESTINATION_WORK  ...  \\\n",
      "0                            1                 0  ...   \n",
      "1                            1                 0  ...   \n",
      "2                            0                 1  ...   \n",
      "3                            0                 1  ...   \n",
      "4                            1                 0  ...   \n",
      "\n",
      "   RESTAURANTLESSTHAN20_1~3  RESTAURANTLESSTHAN20_4~8  \\\n",
      "0                         0                         0   \n",
      "1                         1                         0   \n",
      "2                         1                         0   \n",
      "3                         0                         1   \n",
      "4                         0                         0   \n",
      "\n",
      "   RESTAURANTLESSTHAN20_GT8  RESTAURANTLESSTHAN20_LESS1  \\\n",
      "0                         0                           1   \n",
      "1                         0                           0   \n",
      "2                         0                           0   \n",
      "3                         0                           0   \n",
      "4                         0                           1   \n",
      "\n",
      "   RESTAURANTLESSTHAN20_NEVER  RESTAURANT20TO50_1~3  RESTAURANT20TO50_4~8  \\\n",
      "0                           0                     0                     0   \n",
      "1                           0                     1                     0   \n",
      "2                           0                     1                     0   \n",
      "3                           0                     0                     0   \n",
      "4                           0                     0                     0   \n",
      "\n",
      "   RESTAURANT20TO50_GT8  RESTAURANT20TO50_LESS1  RESTAURANT20TO50_NEVER  \n",
      "0                     0                       1                       0  \n",
      "1                     0                       0                       0  \n",
      "2                     0                       0                       0  \n",
      "3                     0                       1                       0  \n",
      "4                     0                       1                       0  \n",
      "\n",
      "[5 rows x 109 columns]\n",
      "   Y\n",
      "0  1\n",
      "1  1\n",
      "2  1\n",
      "3  0\n",
      "4  1\n",
      "   TEMPERATURE  HAS_CHILDREN  TOCOUPON_GEQ5MIN  TOCOUPON_GEQ15MIN  \\\n",
      "0         30.0           0.0               1.0                1.0   \n",
      "1         80.0           1.0               1.0                1.0   \n",
      "2         55.0           0.0               1.0                0.0   \n",
      "3         30.0           0.0               1.0                0.0   \n",
      "4         55.0           1.0               1.0                1.0   \n",
      "\n",
      "   TOCOUPON_GEQ25MIN  DIRECTION_SAME  DIRECTION_OPP  DESTINATION_HOME  \\\n",
      "0                0.0             0.0            1.0                 1   \n",
      "1                0.0             0.0            1.0                 0   \n",
      "2                0.0             0.0            1.0                 0   \n",
      "3                0.0             0.0            1.0                 0   \n",
      "4                1.0             0.0            1.0                 0   \n",
      "\n",
      "   DESTINATION_NO_URGENT_PLACE  DESTINATION_WORK  ...  \\\n",
      "0                            0                 0  ...   \n",
      "1                            1                 0  ...   \n",
      "2                            1                 0  ...   \n",
      "3                            1                 0  ...   \n",
      "4                            0                 1  ...   \n",
      "\n",
      "   RESTAURANTLESSTHAN20_1~3  RESTAURANTLESSTHAN20_4~8  \\\n",
      "0                         0                         1   \n",
      "1                         0                         1   \n",
      "2                         0                         1   \n",
      "3                         0                         1   \n",
      "4                         0                         0   \n",
      "\n",
      "   RESTAURANTLESSTHAN20_GT8  RESTAURANTLESSTHAN20_LESS1  \\\n",
      "0                         0                           0   \n",
      "1                         0                           0   \n",
      "2                         0                           0   \n",
      "3                         0                           0   \n",
      "4                         1                           0   \n",
      "\n",
      "   RESTAURANTLESSTHAN20_NEVER  RESTAURANT20TO50_1~3  RESTAURANT20TO50_4~8  \\\n",
      "0                           0                     0                     0   \n",
      "1                           0                     0                     0   \n",
      "2                           0                     0                     0   \n",
      "3                           0                     0                     0   \n",
      "4                           0                     0                     0   \n",
      "\n",
      "   RESTAURANT20TO50_GT8  RESTAURANT20TO50_LESS1  RESTAURANT20TO50_NEVER  \n",
      "0                     0                       1                       0  \n",
      "1                     0                       1                       0  \n",
      "2                     0                       1                       0  \n",
      "3                     0                       1                       0  \n",
      "4                     0                       1                       0  \n",
      "\n",
      "[5 rows x 109 columns]\n",
      "   Y\n",
      "0  0\n",
      "1  1\n",
      "2  1\n",
      "3  0\n",
      "4  0\n"
     ]
    }
   ],
   "source": [
    "# Verify columns imported correctly, sometimes an extra index column is present when writing to csv\n",
    "print(X_train.head())\n",
    "print(y_train.head())\n",
    "print(X_test.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simplify our model by creating a variable, `xgb`, which represents the Extreme Gradient Boosting (XGBoost) Classifier. This variable will be used for our XGBoost model throughout the analysis, making it more convenient to refer to and reuse in various sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07cdee69-2553-438d-baf5-466c43a29112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify the model with a variable for later use\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0cfcf-88df-4c33-a22f-a7b0453f111c",
   "metadata": {},
   "source": [
    "The section below sets up the hyperparameters for tuning the model via random search. Due to the large number of combinations, two rounds of tuning will ensue. The first round will feature half the parameters with defaults selected for the others. After the first round, the best model will be used to set a fixed value for the first hyperparameters and the second set will be tested with a distribution via `RandomSearchCV`.\n",
    "\n",
    "These hyperparameters include the criterion used for data splits (`booster`), `max_depth` (round 1), `min_child_weight` (round 1), `subsample` (round 1), `colsample_bytree` (round 1), `learning_rate` (round 2), `gamma` (round 2), and `n_estimators`. These parameters will be explored systematically to optimize the performance of our XGBoost Classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4158125a-5bb1-4115-8c4f-0367ab5252f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion used to guide data splits\n",
    "booster = [\n",
    "    \"gbtree\"\n",
    "]  # This is the default value. Linear booster is rarely used due to poor performance\n",
    "# max_depth round 1 parameter: [int(x) for x in np.linspace(1,100, num=20)]\n",
    "max_depth = [60]  # Any positive value, default 6\n",
    "# min_child_weight round 1 parameter: [int(x) for x in np.linspace(1,10000, num=100)]\n",
    "min_child_weight = [1]  # Any positive value, default 0, larger = less overfitting\n",
    "# subsample round 1 parameter: [x for x in np.linspace(0,1, num=10)]\n",
    "subsample = [\n",
    "    0.77\n",
    "]  # any value 0-1, default 1, lower = less over fitting but may underfit\n",
    "# colsample_bytree round 1 parameter: [x for x in np.linspace(0,1, num=10)]\n",
    "colsample_bytree = [0.44]  # any value 0-1, ratio of colmns selected for each tree\n",
    "# learning_rate round 2 parameter: [x for x in np.linspace(0,1, num=100)]\n",
    "learning_rate = [0.01]  # any value 0-1, default 0.3\n",
    "# gamma round 2 parameter: [0,0.1,1,10 ]\n",
    "gamma = [0, 0.1, 1, 10]  # Any positive value, default 0, larger = conservative\n",
    "# n_estimators round 3 parameter: [int(x) for x in np.linspace(0,1000, num=100)]\n",
    "n_estimators = [\n",
    "    int(x) for x in np.linspace(0, 1000, num=100)\n",
    "]  # Number of trees in model, more = overfit\n",
    "\n",
    "# Tune hyperparameters stepwise\n",
    "# GROUP 1: max_depth , min_child_weight, subsample, colsample_bytree\n",
    "# GROUP 2: learning_rate, gamma,n_estimators\n",
    "\n",
    "# Create the random grid\n",
    "param_grid_random = {\n",
    "    \"booster\": booster,  # Default, stated for clarity\n",
    "    \"max_depth\": max_depth,  # Round 1\n",
    "    \"min_child_weight\": min_child_weight,  # Round 1\n",
    "    \"subsample\": subsample,  # Round 1\n",
    "    \"colsample_bytree\": colsample_bytree,  # Round 1\n",
    "    \"learning_rate\": learning_rate,  # Round 2\n",
    "    \"gamma\": gamma,  # Round 2\n",
    "    \"n_estimators\": n_estimators,  # Round 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we will establish our custom `scorer`. We have decided to use a custom F2 score to prioritize recall (minimizing the chance of not giving a coupon to someone who would use it) while considering the value of precision (minimizing the chance of giving a coupon to someone who will not use it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daf0be03-4c4b-40f1-b281-253ccc39cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom score to optimize model\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute a randomized search to tune our XGBoost model's hyperparameters efficiently. This process involves trying various hyperparameter combinations from the specified `param_grid_random`. The search is conducted using 5-fold cross-validation, and we use the F2 scoring metric to evaluate the model's performance. The `RandomizedSearchCV` is run with a fixed random state for reproducibility, and its execution time is monitored using the `%time` magic command.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ff3353c3-5ba0-4501-a929-5c2862f98cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 3min 56s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-34 {color: black;background-color: white;}#sk-container-id-34 pre{padding: 0;}#sk-container-id-34 div.sk-toggleable {background-color: white;}#sk-container-id-34 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-34 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-34 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-34 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-34 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-34 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-34 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-34 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-34 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-34 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-34 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-34 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-34 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-34 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-34 div.sk-item {position: relative;z-index: 1;}#sk-container-id-34 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-34 div.sk-item::before, #sk-container-id-34 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-34 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-34 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-34 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-34 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-34 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-34 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-34 div.sk-label-container {text-align: center;}#sk-container-id-34 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-34 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-34\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                                          0.25252525252525254,\n",
       "                                                          0.26262626262626265,\n",
       "                                                          0.27272727272727276,\n",
       "                                                          0.2828282828282829,\n",
       "                                                          0.29292929292929293, ...],\n",
       "                                        &#x27;max_depth&#x27;: [60],\n",
       "                                        &#x27;min_child_weight&#x27;: [1],\n",
       "                                        &#x27;n_estimators&#x27;: [0, 10, 20, 30, 40, 50,\n",
       "                                                         60, 70, 80, 90, 101,\n",
       "                                                         111, 121, 131, 141,\n",
       "                                                         151, 161, 171, 181,\n",
       "                                                         191, 202, 212, 222,\n",
       "                                                         232, 242, 252, 262,\n",
       "                                                         272, 282, 292, ...],\n",
       "                                        &#x27;subsample&#x27;: [0.77]},\n",
       "                   random_state=42, scoring=make_scorer(fbeta_score, beta=2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" ><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                                          0.25252525252525254,\n",
       "                                                          0.26262626262626265,\n",
       "                                                          0.27272727272727276,\n",
       "                                                          0.2828282828282829,\n",
       "                                                          0.29292929292929293, ...],\n",
       "                                        &#x27;max_depth&#x27;: [60],\n",
       "                                        &#x27;min_child_weight&#x27;: [1],\n",
       "                                        &#x27;n_estimators&#x27;: [0, 10, 20, 30, 40, 50,\n",
       "                                                         60, 70, 80, 90, 101,\n",
       "                                                         111, 121, 131, 141,\n",
       "                                                         151, 161, 171, 181,\n",
       "                                                         191, 202, 212, 222,\n",
       "                                                         232, 242, 252, 262,\n",
       "                                                         272, 282, 292, ...],\n",
       "                                        &#x27;subsample&#x27;: [0.77]},\n",
       "                   random_state=42, scoring=make_scorer(fbeta_score, beta=2))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" ><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-102\" type=\"checkbox\" ><label for=\"sk-estimator-id-102\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate...\n",
       "                                                          0.25252525252525254,\n",
       "                                                          0.26262626262626265,\n",
       "                                                          0.27272727272727276,\n",
       "                                                          0.2828282828282829,\n",
       "                                                          0.29292929292929293, ...],\n",
       "                                        'max_depth': [60],\n",
       "                                        'min_child_weight': [1],\n",
       "                                        'n_estimators': [0, 10, 20, 30, 40, 50,\n",
       "                                                         60, 70, 80, 90, 101,\n",
       "                                                         111, 121, 131, 141,\n",
       "                                                         151, 161, 171, 181,\n",
       "                                                         191, 202, 212, 222,\n",
       "                                                         232, 242, 252, 262,\n",
       "                                                         272, 282, 292, ...],\n",
       "                                        'subsample': [0.77]},\n",
       "                   random_state=42, scoring=make_scorer(fbeta_score, beta=2))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "random_search = RandomizedSearchCV(xgb, param_grid_random, n_iter=60, cv=5, random_state=42,\n",
    "                                  scoring = f2_scorer, n_jobs = -1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# This code block was used multiple times to tune parameters in a step wise manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then store the best-performing estimator, `best_estimator`, obtained from the randomized search. Additionally, we retrieve the optimal hyperparameters, stored in `best_random_params`, and the highest cross-validation score achieved, indicated by `best_random_score`. These values provide valuable insights into the ideal configuration of our tuned XGBoost Classifier model and its performance on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ae91fc6a-17f1-48b3-8f71-ca2baf675a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'subsample': 0.77,\n",
       "  'n_estimators': 616,\n",
       "  'min_child_weight': 1,\n",
       "  'max_depth': 60,\n",
       "  'learning_rate': 0.010101010101010102,\n",
       "  'gamma': 0,\n",
       "  'colsample_bytree': 0.44,\n",
       "  'booster': 'gbtree'},\n",
       " 0.818844534668821)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store best estimator\n",
    "best_estimator = random_search.best_estimator_\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_random_params = random_search.best_params_\n",
    "best_random_score = random_search.best_score_\n",
    "best_random_params, best_random_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying our best parameters, we will save our preliminary XGBoost model, which was fine-tuned using random search. To assess its performance, we generate predictions on the test dataset, `X_test`, and store them in `y_pred_xgb_random`. We then compute and display the confusion matrix, `cm1`, to spot-check the model's performance, particularly its ability to correctly classify instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "13498ea4-95b4-4ed8-bc0f-4351520caada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 748  330]\n",
      " [ 224 1235]]\n",
      "[[4312   84]\n",
      " [  33 5718]]\n"
     ]
    }
   ],
   "source": [
    "# Save preliminary model and view confusion matrix to spot check\n",
    "# This model had issues with underfitting the data\n",
    "y_pred_xgb_random = best_estimator.predict(X_test)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_pred_xgb_random)\n",
    "print(cm1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first confusion matrix, we see that the model correctly identified 748 instances as negative and 1235 instances as positive, but it made 330 false positive and 224 false negative classifications, indicating a trade-off between precision and recall.\n",
    "\n",
    "In the second confusion matrix, which might be from a different scenario or dataset, the model exhibits impressive performance with a high number of true negatives (4312) and true positives (5718), while making only a small number of false positive (84) and false negative (33) classifications, showcasing its robustness in correctly classifying instances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d1db9-9484-4a06-b0d5-7d028018bb8f",
   "metadata": {},
   "source": [
    "# Second Try - possible underfitting\n",
    "\n",
    "The second try section records the results for my second attempt at hyperparameter tuning as I ran into serious underfitting issues the first time around\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fc594-ab56-4096-a10b-f26d08ec2de8",
   "metadata": {},
   "source": [
    "### Round 1\n",
    "\n",
    "Below are the optimal parameters after round one of random search (time to complete- 39:48). These will be implimented as static values for round two. The round two parameters will now feature a distribution of values instead of defaults. Round one used 1000 random selections from 2 given parameters:\n",
    "\n",
    "1. max_depth\n",
    "2. min_child_weight\n",
    "3. subsample\n",
    "4. colsample_bytree\n",
    "\n",
    "({'subsample': 0.7777777777777777,\n",
    "'min_child_weight': 1,\n",
    "'max_depth': 58,\n",
    "'colsample_bytree': 0.4444444444444444,\n",
    "'booster': 'gbtree'},\n",
    "0.7942921145067275)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd772b3-bdba-4357-8f6f-77ec7a658b85",
   "metadata": {},
   "source": [
    "### Round 2\n",
    "\n",
    "Below are the optimal parameters after round two of random search (time to complete- 1:03:56 mins). These will be implimented as static values for round three. The round two parameters will now feature a distribution of values instead of defaults. Round two used 60 random selections from 3 given parameters and was able to explore all combinations:\n",
    "\n",
    "1. learning_rate\n",
    "2. gamma\n",
    "3. n_estimators\n",
    "\n",
    "({'subsample': 0.77,\n",
    "'n_estimators': 616,\n",
    "'min_child_weight': 1,\n",
    "'max_depth': 60,\n",
    "'learning_rate': 0.010101010101010102,\n",
    "'gamma': 0,\n",
    "'colsample_bytree': 0.44,\n",
    "'booster': 'gbtree'},\n",
    "0.818844534668821)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42cb53b-069f-41e4-be47-ba57a0518bf1",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4ee9ff-0aa9-4648-9b18-fb097dc68542",
   "metadata": {},
   "source": [
    "# First Try - possible underfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb871cee-8e22-4ae4-a6a0-fcc361b5246b",
   "metadata": {},
   "source": [
    "### Round 1 Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b53cac-33ee-4e15-a62b-292d13d16bd2",
   "metadata": {},
   "source": [
    "Below are the optimal parameters after round one of random search (time to complete- 3:07:22). These will be implimented as static values for round two. The round two parameters will now feature a distribution of values instead of defaults. Round one used 7000 random selections from 4 given parameters:\n",
    "\n",
    "1. max_depth\n",
    "2. min_child_weight\n",
    "3. subsample\n",
    "4. colsample_bytree\n",
    "\n",
    "({'subsample': 0.5050505050505051,  \n",
    " 'min_child_weight': 950,  \n",
    " 'max_depth': 11,  \n",
    " 'colsample_bytree': 0.33333333333333337,  \n",
    " 'booster': 'gbtree'},\n",
    "0.8673946364835304)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902a5e9-2430-4ec0-8fbe-5a358b1cd27d",
   "metadata": {},
   "source": [
    "### Round 2 Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fab9bc-d76c-4542-856b-0e3033d70a3d",
   "metadata": {},
   "source": [
    "Below are the optimal parameters after round two of random search (time to complete- 34 mins). These will be implimented as static values for round three. The round two parameters will now feature a distribution of values instead of defaults. Round two used 1400 random selections from 2 given parameters and was able to explore all combinations:\n",
    "\n",
    "1. learning_rate\n",
    "2. gamma\n",
    "\n",
    "({'subsample': 0.5,  \n",
    " 'min_child_weight': 950,  \n",
    " 'max_depth': 11,  \n",
    " 'learning_rate': 0.010101010101010102,  \n",
    " 'gamma': 0.001,  \n",
    " 'colsample_bytree': 0.33,  \n",
    " 'booster': 'gbtree'},  \n",
    " 0.8673946364835304)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be76dc-5719-4f6d-9740-8cbc79bc4357",
   "metadata": {},
   "source": [
    "### Round 3 Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df30d1-6384-4f28-a1a5-e6c8c22e4a38",
   "metadata": {},
   "source": [
    "Round three yeilded the result that 10 was the optimal number for n_estimators given the other static parameters. Training time was 12:03. Results were as follows:\n",
    "\n",
    "({'subsample': 0.5,  \n",
    " 'n_estimators': 10,  \n",
    " 'min_child_weight': 950,  \n",
    " 'max_depth': 11,  \n",
    " 'learning_rate': 0.01,  \n",
    " 'gamma': 0.001,  \n",
    " 'colsample_bytree': 0.33,  \n",
    " 'booster': 'gbtree'},  \n",
    " 0.8673946364835304)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f99e6e-92e9-46d6-a2dd-09fc64c1b5ff",
   "metadata": {},
   "source": [
    "### Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8fe161-62c2-4ab2-9cd8-84453b8cc82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion used to guide data splits\n",
    "booster = [\n",
    "    \"gbtree\"\n",
    "]  # This is the default value. Linear booster is rarely used due to poor performance\n",
    "max_depth = [50, 60, 70]  # Any positive value, default 6\n",
    "min_child_weight = [\n",
    "    1,\n",
    "    5,\n",
    "    10,\n",
    "]  # Any positive value, default 0, larger = less overfitting\n",
    "subsample = [\n",
    "    0.7,\n",
    "    0.8,\n",
    "    0.9,\n",
    "]  # any value 0-1, default 1, lower = less over fitting but may underfit\n",
    "colsample_bytree = [\n",
    "    0.4,\n",
    "    0.45,\n",
    "    0.5,\n",
    "]  # any value 0-1, ratio of colmns selected for each tree\n",
    "learning_rate = [0.01, 0.05]  # any value 0-1, default 0.3\n",
    "gamma = [0, 1, 10]  # Any positive value, default 0, larger = conservative\n",
    "n_estimators = [500, 600, 700]  # Number of trees in model, more = overfit\n",
    "\n",
    "# Create the grid\n",
    "param_grid = {\n",
    "    \"booster\": booster,  # Default, stated for clarity\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_child_weight\": min_child_weight,\n",
    "    \"subsample\": subsample,\n",
    "    \"colsample_bytree\": colsample_bytree,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"gamma\": gamma,\n",
    "    \"n_estimators\": n_estimators,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a grid search to further fine-tune our XGBoost model, systematically exploring hyperparameter combinations specified in `param_grid`. This process is conducted with 5-fold cross-validation and utilizes the F2 scoring metric for evaluation. The `%time` magic command is used to monitor the execution time of this grid search operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4e3da7b-7498-4da5-a758-8049a43ebe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\Users\\baker\\miniconda3\\envs\\snowflakes\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 1s\n",
      "Wall time: 43min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_grid_search_model = GridSearchCV(xgb, param_grid, cv = 5,\n",
    "                                      scoring=f2_scorer, n_jobs = -1)\n",
    "\n",
    "_ = best_grid_search_model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the best model through grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08ff50f1-903d-4260-a3ba-5c85de630ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'booster': 'gbtree',\n",
       "  'colsample_bytree': 0.4,\n",
       "  'gamma': 0,\n",
       "  'learning_rate': 0.01,\n",
       "  'max_depth': 50,\n",
       "  'min_child_weight': 1,\n",
       "  'n_estimators': 500,\n",
       "  'subsample': 0.7},\n",
       " 0.8221619337168005)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters and score\n",
    "best_params = best_grid_search_model.best_params_\n",
    "best_score = best_grid_search_model.best_score_\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Our Best Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the final pipeline for our XGBoost Classifier, incorporating the optimal hyperparameters obtained from the grid search. The pipeline consists of the `XGBClassifier` with the following hyperparameter settings: `booster=\"gbtree\"`, `colsample_bytree=0.4`, `gamma=0`, `learning_rate=0.01`, `max_depth=50`, `min_child_weight=1`, `n_estimators=500`, and `subsample=0.7`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final pipeline\n",
    "xgb_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"xgb\",\n",
    "            XGBClassifier(\n",
    "                booster=\"gbtree\",\n",
    "                colsample_bytree=0.4,\n",
    "                gamma=0,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=50,\n",
    "                min_child_weight=1,\n",
    "                n_estimators=500,\n",
    "                subsample=0.7,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train our final XGBoost pipeline, `xgb_pipeline`, on the training data, `X_train` and `y_train`, to develop a robust and optimized XGBoost Classifier model that will be used for subsequent predictions and evaluations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                               callbacks=None, colsample_bylevel=None,\n",
       "                               colsample_bynode=None, colsample_bytree=0.4,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=0, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.01,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=50, max_leaves=None,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=500,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                               callbacks=None, colsample_bylevel=None,\n",
       "                               colsample_bynode=None, colsample_bytree=0.4,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=0, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.01,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=50, max_leaves=None,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=500,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.4, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=50, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=500, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('xgb',\n",
       "                 XGBClassifier(base_score=None, booster='gbtree',\n",
       "                               callbacks=None, colsample_bylevel=None,\n",
       "                               colsample_bynode=None, colsample_bytree=0.4,\n",
       "                               early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=0, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.01,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=50, max_leaves=None,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=500,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the final pipeline\n",
    "xgb_pipeline.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate predictions on the test dataset, `X_test`, using our trained XGBoost Classifier model, storing the results in `y_pred_xgb`. These predictions will be used for evaluating the model's performance on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "866b0a40-c9b8-4f12-bd07-819399a8df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgb_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the confusion matrix, `cm`, to assess the performance of our XGBoost Classifier model on the test data. The matrix provides details on the number of true negatives, false positives, false negatives, and true positives, allowing us to evaluate the model's classification accuracy and potential areas for improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7350290-a98d-48f2-ad5c-f3bce52238a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 730  348]\n",
      " [ 220 1239]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In analyzing the confusion matrix for our final XGBoost Classifier model, we observe that the model correctly classified 730 instances as negative and 1239 instances as positive, indicating its ability to correctly identify both classes. However, it made 348 false positive and 220 false negative classifications, which implies a trade-off between precision and recall. While the model demonstrates decent performance, further optimization may be necessary to balance these two aspects and enhance its overall accuracy, especially in scenarios where minimizing false positives or false negatives is critical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d9bf6f-fdf2-476f-87a7-a4b4836a8ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8345682338677085"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbeta_score(y_test, y_pred_xgb, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F2 score for our final XGBoost Classifier model, calculated using the provided test data and predictions, is approximately 0.8345. This score reflects the model's ability to balance precision and recall, with an emphasis on recall, making it suitable for scenarios where minimizing false negatives is important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling Our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1543d06e-13cd-4c5a-8607-74fdac2b1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename where you want to save the model\n",
    "filename = \"XGB_Model.pkl\"\n",
    "\n",
    "# Export the model to the file using pickle.dump\n",
    "with open(filename, \"wb\") as file:\n",
    "    pickle.dump(xgb_pipeline, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
