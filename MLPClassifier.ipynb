{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f282a5-f562-48a5-b060-d675ea3c3308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95388a4c-625e-485d-8ae7-ab4bdda21f74",
   "metadata": {},
   "source": [
    "# Neural Network MLP Classifier\n",
    "\n",
    "In this section, we delve into the realm of artificial neural networks by exploring the Multi-Layer Perceptron (MLP) Classifier. MLP is a class of feedforward artificial neural network that consists of multiple layers of nodes, each layer fully connected to the next one. It is designed to model complex patterns in data by learning multiple layers of representation.\n",
    "\n",
    "## Key Characteristics of Neural Network MLP:\n",
    "\n",
    "- **Layered Architecture**: MLPs consist of an input layer, several hidden layers, and an output layer, allowing the model to learn at various levels of abstraction.\n",
    "- **Nonlinear Activation**: Nonlinear activation functions within neurons enable the network to capture complex relationships between features.\n",
    "- **Backpropagation**: MLP uses backpropagation for training, efficiently adjusting weights in the network through gradient descent.\n",
    "\n",
    "MLPs are powerful tools capable of modeling complex and high-dimensional data, making them suitable for a wide range of classification tasks, from image recognition to natural language processing.\n",
    "\n",
    "The objective of this notebook is to develop, fine-tune, and assess an MLP Classifier's performance, preparing it for subsequent comparison with other classification models in a broader study.\n",
    "\n",
    "For an in-depth walkthrough of our setup process, please refer to the notebook \"Final_Project_Data_Gen.\"\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our dataset from CSV files, with `X_train` and `y_train` as our training features and labels, and `X_test` and `y_test` for testing, using Pandas DataFrames to facilitate data manipulation and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396ae859-f9d6-4221-9e39-e8ecd3910872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"train_X_In-Car-Rec.csv\")\n",
    "y_train = pd.read_csv(\"train_y_In-Car-Rec.csv\")\n",
    "X_test = pd.read_csv(\"test_X_In-Car-Rec.csv\")\n",
    "y_test = pd.read_csv(\"test_y_In-Car-Rec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a `param_grid` for fine-tuning our Multi-Layer Perceptron (MLP) classifier, specifying different architectures for `hidden_layer_sizes` to test single and multiple layers of various sizes. We also explore several `activation` functions to determine which helps our network learn best, and we vary `max_iter` to give our model sufficient iterations to converge during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c197f221-1ead-448e-8a94-991f312bbedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"mlp__hidden_layer_sizes\": [(100,), (50, 50), (50, 25, 10), (40, 20, 10)],\n",
    "    \"mlp__activation\": [\"logistic\", \"tanh\", \"relu\"],\n",
    "    \"mlp__max_iter\": [1000, 5000, 10000],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we will establish our custom `scorer`. We have decided to use a custom F2 score to prioritize recall (minimizing the chance of not giving a coupon to someone who would use it) while considering the value of precision (minimizing the chance of giving a coupon to someone who will not use it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f5c97a-30c3-4054-b10b-fc2aca71b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function\n",
    "scorer = make_scorer(fbeta_score, beta=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a comprehensive pipeline named `pipeline` that encapsulates the MLPClassifier. This setup streamlines the process of standardizing our workflow, making it straightforward to include additional preprocessing steps in the future if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05969f88-067e-486c-8164-dd752bf9e016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the full pipeline\n",
    "pipeline = Pipeline([(\"mlp\", MLPClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a `GridSearchCV` object that applies an exhaustive search over the specified `param_grid` for our neural network pipeline. By setting `cv=3`, we use 3-fold cross-validation to assess each set of parameters, and we specify our performance metric with the `scoring` object. Finally, we fit this grid search to our training data, allowing us to identify the best hyperparameter combination for our MLPClassifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e4fbbd-5341-4b4a-aa89-cac505fbd891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=Pipeline(steps=[(&#x27;mlp&#x27;, MLPClassifier())]),\n",
       "             param_grid={&#x27;mlp__activation&#x27;: [&#x27;logistic&#x27;, &#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;mlp__hidden_layer_sizes&#x27;: [(100,), (50, 50),\n",
       "                                                     (50, 25, 10),\n",
       "                                                     (40, 20, 10)],\n",
       "                         &#x27;mlp__max_iter&#x27;: [1000, 5000, 10000]},\n",
       "             scoring=make_scorer(fbeta_score, beta=2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=Pipeline(steps=[(&#x27;mlp&#x27;, MLPClassifier())]),\n",
       "             param_grid={&#x27;mlp__activation&#x27;: [&#x27;logistic&#x27;, &#x27;tanh&#x27;, &#x27;relu&#x27;],\n",
       "                         &#x27;mlp__hidden_layer_sizes&#x27;: [(100,), (50, 50),\n",
       "                                                     (50, 25, 10),\n",
       "                                                     (40, 20, 10)],\n",
       "                         &#x27;mlp__max_iter&#x27;: [1000, 5000, 10000]},\n",
       "             scoring=make_scorer(fbeta_score, beta=2))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;mlp&#x27;, MLPClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=Pipeline(steps=[('mlp', MLPClassifier())]),\n",
       "             param_grid={'mlp__activation': ['logistic', 'tanh', 'relu'],\n",
       "                         'mlp__hidden_layer_sizes': [(100,), (50, 50),\n",
       "                                                     (50, 25, 10),\n",
       "                                                     (40, 20, 10)],\n",
       "                         'mlp__max_iter': [1000, 5000, 10000]},\n",
       "             scoring=make_scorer(fbeta_score, beta=2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring=scorer)\n",
    "\n",
    "# Fit the pipeline (including hyperparameter tuning) to your data\n",
    "grid_search.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will retrieve and store the best-performing model from our grid search in the variable `best_estimator`. Additionally, we extract the optimal set of hyperparameters and the highest cross-validation score obtained during the search, assigning them to `best_random_params` and `best_random_score` respectively. These variables give us insight into the most effective configuration of our MLPClassifier and its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1af0c9ef-b5a0-4706-be2a-d796bf9d0bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mlp__activation': 'logistic',\n",
       "  'mlp__hidden_layer_sizes': (100,),\n",
       "  'mlp__max_iter': 1000},\n",
       " 0.7743742278414341)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store best estimator\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_random_params = grid_search.best_params_\n",
    "best_random_score = grid_search.best_score_\n",
    "\n",
    "best_random_params, best_random_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct our final pipeline, `pipeline_MLP`, which is configured with an `MLPClassifier`. The classifier is set with a logistic activation function, a single hidden layer of 100 neurons, and a maximum of 1000 iterations for the training process. This pipeline encapsulates our chosen model configuration for the MLP, ready for training and subsequent evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a93f961-5f76-40ac-929d-4afcec1e8040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final pipeline\n",
    "pipeline_MLP = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"mlp\",\n",
    "            MLPClassifier(\n",
    "                activation=\"logistic\",\n",
    "                hidden_layer_sizes=(100,),\n",
    "                max_iter=1000,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train our final MLP pipeline, `pipeline_MLP`, using the training data `X_train` and the target values `y_train`. By using the `ravel()` method, we ensure that the `y_train` data is in the correct shape for the fitting process, which is a one-dimensional array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "505e4ff2-896b-438a-b440-6f55017ff81a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;mlp&#x27;, MLPClassifier(activation=&#x27;logistic&#x27;, max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;mlp&#x27;, MLPClassifier(activation=&#x27;logistic&#x27;, max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, max_iter=1000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('mlp', MLPClassifier(activation='logistic', max_iter=1000))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the final pipeline\n",
    "pipeline_MLP.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make predictions on the test dataset `X_test`. The predicted labels for the test data are stored in `y_pred`, which we will use for evaluating the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8499070-e7b8-43b6-92f4-41696b802099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = pipeline_MLP.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the performance of our MLP pipeline on the test data `X_test` by using the `score` method, which provides the accuracy of the model. Additionally, we calculate the weighted F2 score, which places more emphasis on recall, using the `fbeta_score` function with `beta=2`. This score is particularly useful for imbalanced classes. The calculated F2 score is then printed to give us a more nuanced understanding of our model's predictive capability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d91333a4-1596-425e-bd71-6dc01817379a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F2Score for the MLP Classifier Model is: 0.7412090067455147\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the pipeline on the test data\n",
    "score = pipeline_MLP.score(X_test, y_test)\n",
    "\n",
    "# Calculate f1_score on the test data\n",
    "f2_score = fbeta_score(y_test, y_pred, average=\"weighted\", beta=2)\n",
    "print(f\"F2Score for the MLP Classifier Model is: \" + str(f2_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F2Score for our MLP Classifier Model is approximately 0.7412, indicating a model performance that balances precision and recall, with an emphasis on recall. This suggests that our model is adept at correctly identifying positive instances in the test data, particularly valuable in situations where minimizing false negatives is crucial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a comprehensive evaluation of our MLP Classifier model's performance:\n",
    "\n",
    "- **Confusion Matrix**: We calculate a confusion matrix to visualize the model's predictions and actual outcomes, providing insights into true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "- **Precision (weighted)**: We compute the weighted precision, which gives us an overall measure of how often the model's positive predictions are correct, accounting for class imbalance.\n",
    "\n",
    "- **Recall (weighted)**: The weighted recall is determined, reflecting the model's ability to correctly identify positive instances while considering class distribution.\n",
    "\n",
    "- **Accuracy**: We calculate the overall accuracy of the model, representing the proportion of correct predictions among all predictions made.\n",
    "\n",
    "These metrics collectively provide a comprehensive view of the MLP Classifier model's effectiveness in making predictions on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b766858-66ef-4b29-bd5c-1ecd9cc5397c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 769  309]\n",
      " [ 348 1111]]\n",
      "\n",
      "Precision (weighted): 0.7425\n",
      "Recall (weighted): 0.7410\n",
      "Accuracy: 0.7410\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "print(f\"\\nPrecision (weighted): {precision:.4f}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "print(f\"Recall (weighted): {recall:.4f}\")\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Confusion Matrix shows that our MLP Classifier model made 769 true negative predictions, 1111 true positive predictions, 309 false positive predictions, and 348 false negative predictions.\n",
    "\n",
    "The weighted Precision, measuring the accuracy of positive predictions, is approximately 0.7425. The weighted Recall, which assesses the model's ability to identify positive instances, stands at approximately 0.7410.\n",
    "\n",
    "The overall Accuracy of our model is approximately 0.7410, indicating that it correctly predicts around 74.10% of instances in the test data. These metrics collectively provide an understanding of our model's performance on the test dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickling Our Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the filename where you want to save the model\n",
    "filename = \"MLP_Model.pkl\"\n",
    "\n",
    "# Export the model to the file using pickle.dump\n",
    "with open(filename, \"wb\") as file:\n",
    "    pickle.dump(pipeline_MLP, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
